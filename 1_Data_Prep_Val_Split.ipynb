{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1. Data Prep:**\n",
        "\n",
        "*Using FaceForensics++ Dataset from Kaggle*"
      ],
      "metadata": {
        "id": "H6-G1-U_48GA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIREgCfbzp_3"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/drive/MyDrive/ff++dataset\""
      ],
      "metadata": {
        "id": "QDkiXhRU0Ciy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing libs\n",
        "import os\n",
        "import cv2 as cv\n",
        "import dlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import h5py"
      ],
      "metadata": {
        "id": "fI4cSZ6v0EQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.1 Frame Extraction:**"
      ],
      "metadata": {
        "id": "LTVWxsey5Yds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#extract frames from one video\n",
        "def extract_frames(video_path, output_folder, frame_rate=1, frame_prefix=\"\"):\n",
        "    \"\"\"\n",
        "    Extracts frames from a video, skipping frames that already exist.\n",
        "\n",
        "    Args:\n",
        "        video_path (str): Path to the input video file.\n",
        "        output_folder (str): Path to the folder where frames will be saved.\n",
        "        frame_rate (int): Desired frame rate (frames per second).\n",
        "        frame_prefix (str): Prefix for the saved frame filenames.\n",
        "    \"\"\"\n",
        "    cap = cv.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error: Could not open video file {video_path}\")\n",
        "        return\n",
        "\n",
        "    fps = cap.get(cv.CAP_PROP_FPS)\n",
        "    frame_interval = int(fps / frame_rate)\n",
        "    frame_count = 0\n",
        "    saved_count = 0\n",
        "\n",
        "    while True:\n",
        "        read_frame, frame_data = cap.read()\n",
        "        if not read_frame:\n",
        "            break\n",
        "\n",
        "        if frame_count % frame_interval == 0:\n",
        "            frame_filename = os.path.join(output_folder, f\"{frame_prefix}_{saved_count:06d}.jpg\")\n",
        "\n",
        "            # Check if the frame already exists\n",
        "            if not os.path.exists(frame_filename):\n",
        "                cv.imwrite(frame_filename, frame_data)\n",
        "                saved_count += 1\n",
        "            else:\n",
        "                print(f\"Frame already exists: {frame_filename}\")\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "    cap.release()\n",
        "    print(f\"Extracted {saved_count} frames from {video_path}\")"
      ],
      "metadata": {
        "id": "3xzwjxrS0GXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extract frames from whole dataset\n",
        "def extract_frames_from_dataset(dataset_path, output_folder, frame_rate=1):\n",
        "    \"\"\"\n",
        "    Extracts frames from all videos in a dataset, organized by class (real/fake).\n",
        "\n",
        "    Args:\n",
        "        dataset_path (str): Path to the dataset folder.\n",
        "        output_folder (str): Path to the folder where extracted frames will be saved.\n",
        "        frame_rate (int): Desired frame rate.\n",
        "    \"\"\"\n",
        "    for class_name in [\"real\", \"fake\"]:\n",
        "        class_path = os.path.join(dataset_path, class_name)\n",
        "        output_class_folder = os.path.join(output_folder, class_name)\n",
        "        os.makedirs(output_class_folder, exist_ok=True)\n",
        "\n",
        "        for video_name in os.listdir(class_path):\n",
        "            video_path = os.path.join(class_path, video_name)\n",
        "            frame_prefix = video_name.split('.mp4')[0]\n",
        "\n",
        "            extract_frames(video_path, output_class_folder, frame_rate, frame_prefix=frame_prefix)\n",
        "\n",
        "\n",
        "dataset_path = \"/content/drive/MyDrive/ff++dataset\"\n",
        "output_folder = \"/content/drive/MyDrive/ff++extracted_frames\"\n",
        "extract_frames_from_dataset(dataset_path, output_folder)"
      ],
      "metadata": {
        "id": "yxifEDWL0Iva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.2 Frame Preprocessing:**"
      ],
      "metadata": {
        "id": "szACJ9VT5qMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Dlib's face detector and shape predictor\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor(\"/content/drive/MyDrive/shape_predictor_68_face_landmarks.dat\")"
      ],
      "metadata": {
        "id": "cu1523VN0K_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image, target_size=(224, 224)):\n",
        "    \"\"\"\n",
        "    Preprocess the image: detect, align, crop, resize, and normalize.\n",
        "    Handles multiple faces in the image.\n",
        "    \"\"\"\n",
        "    # Convert the image to grayscale for face detection\n",
        "    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Detect faces in the image\n",
        "    faces = detector(gray)\n",
        "    if len(faces) == 0:\n",
        "        return []  # No face detected, return an empty list\n",
        "\n",
        "    preprocessed_faces = []\n",
        "\n",
        "    # Process each detected face\n",
        "    for face in faces:\n",
        "        # Get facial landmarks\n",
        "        landmarks = predictor(gray, face)\n",
        "\n",
        "        # Align the face using Dlib's get_face_chip\n",
        "        aligned_face = dlib.get_face_chip(image, landmarks)\n",
        "\n",
        "        # Convert the aligned face to a NumPy array\n",
        "        aligned_face_np = np.array(aligned_face)\n",
        "\n",
        "        # Check if the aligned face is valid\n",
        "        if aligned_face_np.size == 0:\n",
        "            print(\"Warning: Aligned face is empty.\")\n",
        "            continue\n",
        "\n",
        "        # Resize the face to the target size\n",
        "        resized_face = cv.resize(aligned_face_np, target_size)\n",
        "\n",
        "        # Normalize the pixel values to [0, 1]\n",
        "        normalized_face = resized_face / 255.0\n",
        "\n",
        "        # Append the preprocessed face to the list\n",
        "        preprocessed_faces.append(normalized_face)\n",
        "\n",
        "    return preprocessed_faces"
      ],
      "metadata": {
        "id": "yMZ4KQw80NH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_dataset(input_folder, output_folder, target_size=(224, 224)):\n",
        "    \"\"\"\n",
        "    Preprocess all frames in the input folder and save them to the output folder.\n",
        "    Handles multiple faces in each frame.\n",
        "    \"\"\"\n",
        "    # Create the output folder if it doesn't exist\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Initialize lists to store preprocessed data and labels\n",
        "    preprocessed_data = []\n",
        "    labels = []\n",
        "\n",
        "    # Iterate through all classes (e.g., \"real\" and \"fake\")\n",
        "    for class_name in [\"real\", \"fake\"]:\n",
        "        class_input_path = os.path.join(input_folder, class_name)\n",
        "        class_output_path = os.path.join(output_folder, class_name)\n",
        "        os.makedirs(class_output_path, exist_ok=True)\n",
        "\n",
        "        # Iterate through all frames in the class folder\n",
        "        for frame_name in os.listdir(class_input_path):\n",
        "            frame_input_path = os.path.join(class_input_path, frame_name)\n",
        "\n",
        "            # Remove the .jpg extension from the frame name\n",
        "            frame_base_name = os.path.splitext(frame_name)[0]  # Removes .jpg\n",
        "\n",
        "            # Load the frame\n",
        "            image = cv.imread(frame_input_path)\n",
        "            if image is None:\n",
        "                print(f\"Error: Could not load image {frame_input_path}\")\n",
        "                continue\n",
        "\n",
        "            # Preprocess the frame (detect and process all faces)\n",
        "            preprocessed_faces = preprocess_image(image, target_size)\n",
        "            if not preprocessed_faces:\n",
        "                print(f\"No face detected or alignment failed in {frame_input_path}\")\n",
        "                continue\n",
        "\n",
        "            # Save each preprocessed face and append to the lists\n",
        "            for i, face in enumerate(preprocessed_faces):\n",
        "                # Save the preprocessed face\n",
        "                face_output_path = os.path.join(class_output_path, f\"{frame_base_name}_face_{i}.jpg\")\n",
        "                face_image = (face * 255).astype(np.uint8)  # Convert back to [0, 255] for saving\n",
        "                cv.imwrite(face_output_path, face_image)\n",
        "\n",
        "                # Append the preprocessed face and label to the lists\n",
        "                preprocessed_data.append(face)\n",
        "                labels.append(0 if class_name == \"real\" else 1)  # 0 for real, 1 for fake\n",
        "\n",
        "    # Convert lists to NumPy arrays\n",
        "    preprocessed_data = np.array(preprocessed_data)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    return preprocessed_data, labels"
      ],
      "metadata": {
        "id": "fEwBs0fB0PZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input and output folders\n",
        "input_folder = \"/content/drive/MyDrive/ff++extracted_frames\"\n",
        "output_folder = \"/content/drive/MyDrive/ff++preprocessed_frames\"\n",
        "\n",
        "# Preprocess the dataset\n",
        "preprocess_dataset(input_folder, output_folder)\n",
        "\n",
        "# Print the shapes of the preprocessed data and labels\n",
        "print(\"Preprocessed data shape:\", preprocessed_data.shape)\n",
        "print(\"Labels shape:\", labels.shape)"
      ],
      "metadata": {
        "id": "et3Eb_K-0SwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.3 Loading Preprocessed Data**"
      ],
      "metadata": {
        "id": "8R5IuA5p59Ll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_preprocessed_data(preprocessed_folder):\n",
        "    \"\"\"\n",
        "    Load preprocessed data and labels from the output folder.\n",
        "    Assumes the output folder has the same structure as the input folder.\n",
        "\n",
        "    Args:\n",
        "        preprocessed_folder (str): Path to the folder containing preprocessed data.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing:\n",
        "            - preprocessed_data (np.array): Array of preprocessed images.\n",
        "            - labels (np.array): Array of labels (0 for real, 1 for fake).\n",
        "    \"\"\"\n",
        "    # Initialize lists to store preprocessed data and labels\n",
        "    preprocessed_data = []\n",
        "    labels = []\n",
        "\n",
        "    # Iterate through all classes (e.g., \"real\" and \"fake\")\n",
        "    for class_name in [\"real\", \"fake\"]:\n",
        "        class_output_path = os.path.join(preprocessed_folder, class_name)\n",
        "\n",
        "        # Iterate through all preprocessed face files in the class folder\n",
        "        for face_file in os.listdir(class_output_path):\n",
        "            face_file_path = os.path.join(class_output_path, face_file)\n",
        "\n",
        "            # Load the preprocessed face image\n",
        "            face_image = cv.imread(face_file_path)\n",
        "            if face_image is None:\n",
        "                print(f\"Error: Could not load preprocessed face {face_file_path}\")\n",
        "                continue\n",
        "\n",
        "            # Normalize the face image to [0, 1]\n",
        "            normalized_face = face_image / 255.0\n",
        "\n",
        "            # Append the preprocessed face and label to the lists\n",
        "            preprocessed_data.append(normalized_face)\n",
        "            labels.append(0 if class_name == \"real\" else 1)  # 0 for real, 1 for fake\n",
        "\n",
        "            # Print the name of the image being stored\n",
        "            print(f\"Stored image: {face_file} (Class: {class_name})\")\n",
        "\n",
        "    # Convert lists to NumPy arrays\n",
        "    preprocessed_data = np.array(preprocessed_data)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    return preprocessed_data, labels"
      ],
      "metadata": {
        "id": "A0Hb-BUs0XoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define output folder\n",
        "preprocessed_folder = \"/content/drive/MyDrive/ff++preprocessed_frames\"\n",
        "\n",
        "# Load preprocessed data and labels\n",
        "preprocessed_data, labels = load_preprocessed_data(preprocessed_folder)\n",
        "\n",
        "# Print the shapes of the preprocessed data and labels\n",
        "print(\"Preprocessed data shape:\", preprocessed_data.shape)\n",
        "print(\"Labels shape:\", labels.shape)"
      ],
      "metadata": {
        "id": "LCyG07ZH0Z76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.4 Saving Preprocessed Data Class-wise(Real/Fake) in .h5 format**"
      ],
      "metadata": {
        "id": "EHLyyZmQ6aeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_class_data(preprocessed_folder, class_name, output_path):\n",
        "    \"\"\"\n",
        "    Process and save data for a specific class (real or fake) to an HDF5 file incrementally.\n",
        "    Skips frames that have already been processed and saved.\n",
        "\n",
        "    Args:\n",
        "        preprocessed_folder (str): Path to the folder containing preprocessed data.\n",
        "        class_name (str): Name of the class (\"real\" or \"fake\").\n",
        "        output_path (str): Path to save the HDF5 file.\n",
        "    \"\"\"\n",
        "    # Path to the class folder\n",
        "    class_output_path = os.path.join(preprocessed_folder, class_name)\n",
        "\n",
        "    # Check if the HDF5 file already exists and handle overwriting\n",
        "    if os.path.exists(output_path):\n",
        "        os.remove(output_path)\n",
        "        print(f\"Overwriting existing HDF5 file: {output_path}\")\n",
        "    else:\n",
        "        print(f\"Creating new HDF5 file: {output_path}\")\n",
        "\n",
        "    # Open the HDF5 file in write mode\n",
        "    with h5py.File(output_path, \"w\") as f:\n",
        "        # Create datasets\n",
        "        f.create_dataset(\n",
        "            \"preprocessed_data\",\n",
        "            shape=(0, 224, 224, 3),  # Consistent with your sample image shape\n",
        "            maxshape=(None, 224, 224, 3),\n",
        "            dtype=np.uint8,\n",
        "            compression=\"gzip\",\n",
        "        )\n",
        "        f.create_dataset(\n",
        "            \"labels\",\n",
        "            shape=(0,),\n",
        "            maxshape=(None,),\n",
        "            dtype=np.uint8,\n",
        "            compression=\"gzip\",\n",
        "        )\n",
        "        f.create_dataset(\n",
        "            \"frame_names\",\n",
        "            shape=(0,),\n",
        "            maxshape=(None,),\n",
        "            dtype=h5py.string_dtype(encoding=\"utf-8\"),\n",
        "            compression=\"gzip\",\n",
        "        )\n",
        "\n",
        "        # Iterate through all preprocessed face files in the class folder\n",
        "        for face_file in os.listdir(class_output_path):\n",
        "            face_file_path = os.path.join(class_output_path, face_file)\n",
        "\n",
        "            # Load the preprocessed face image\n",
        "            face_image = cv.imread(face_file_path)\n",
        "            if face_image is None:\n",
        "                print(f\"Error: Could not load preprocessed face {face_file_path}\")\n",
        "                continue\n",
        "\n",
        "            # Check if the image has the correct shape\n",
        "            if face_image.shape != (224, 224, 3):\n",
        "                print(f\"Warning: Image {face_file} has shape {face_image.shape}, expected (224, 224, 3). Skipping.\")\n",
        "                continue\n",
        "\n",
        "            # Append the preprocessed face and label to the datasets\n",
        "            f[\"preprocessed_data\"].resize((f[\"preprocessed_data\"].shape[0] + 1), axis=0)\n",
        "            f[\"preprocessed_data\"][-1] = face_image  # No normalization needed if saving as uint8\n",
        "\n",
        "            f[\"labels\"].resize((f[\"labels\"].shape[0] + 1), axis=0)\n",
        "            f[\"labels\"][-1] = 0 if class_name == \"real\" else 1  # 0 for real, 1 for fake\n",
        "\n",
        "            f[\"frame_names\"].resize((f[\"frame_names\"].shape[0] + 1), axis=0)\n",
        "            f[\"frame_names\"][-1] = face_file.encode(\"utf-8\") # encode to utf-8\n",
        "\n",
        "            # Print the name of the image being stored\n",
        "            print(f\"Stored image: {face_file} (Class: {class_name})\")\n",
        "\n",
        "    print(f\"Data for class '{class_name}' saved to: {output_path}\")\n"
      ],
      "metadata": {
        "id": "-G4QZxmi0efJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving Preprocessed Real Class in real_data.h5\n",
        "save_class_data(preprocessed_folder, \"real\", real_output_path)"
      ],
      "metadata": {
        "id": "pgWXhB-K1M3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving Preprocessed Fake Class in fake_data.h5\n",
        "save_class_data(preprocessed_folder, \"fake\", fake_output_path)"
      ],
      "metadata": {
        "id": "fcPm8l_C1Nk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.5 Saving both classes into single .h5 file**"
      ],
      "metadata": {
        "id": "K1nc0qDD6pmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths\n",
        "combined_output_path = \"/content/drive/MyDrive/ff++preprocessed_combined_data.h5\"\n",
        "real_output_path = \"/content/drive/MyDrive/ff++preprocessed_real_data.h5\"\n",
        "fake_output_path = \"/content/drive/MyDrive/ff++preprocessed_fake_data.h5\""
      ],
      "metadata": {
        "id": "2SWp5pIx0kzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty combined file with correct datasets\n",
        "with h5py.File(combined_output_path, \"w\") as combined_file:\n",
        "    combined_file.create_dataset(\"preprocessed_data\", shape=(0, 224, 224, 3), maxshape=(None, 224, 224, 3), dtype=np.uint8, compression=\"gzip\")\n",
        "    combined_file.create_dataset(\"labels\", shape=(0,), maxshape=(None,), dtype=np.uint8, compression=\"gzip\")\n",
        "    combined_file.create_dataset(\"frame_names\", shape=(0,), maxshape=(None,), dtype=h5py.string_dtype(encoding=\"utf-8\"), compression=\"gzip\")\n",
        "#Append Real Data\n",
        "with h5py.File(real_output_path, \"r\") as real_file, h5py.File(combined_output_path, \"a\") as combined_file:\n",
        "    real_data = real_file[\"preprocessed_data\"][:]\n",
        "    real_labels = real_file[\"labels\"][:]\n",
        "    real_frame_names = real_file[\"frame_names\"][:]\n",
        "\n",
        "    current_len = combined_file[\"preprocessed_data\"].shape[0]\n",
        "\n",
        "    combined_file[\"preprocessed_data\"].resize((current_len + real_data.shape[0]), axis=0)\n",
        "    combined_file[\"labels\"].resize((current_len + real_labels.shape[0]), axis=0)\n",
        "    combined_file[\"frame_names\"].resize((current_len + real_frame_names.shape[0]), axis=0)\n",
        "\n",
        "    combined_file[\"preprocessed_data\"][current_len:] = real_data\n",
        "    combined_file[\"labels\"][current_len:] = real_labels\n",
        "    combined_file[\"frame_names\"][current_len:] = real_frame_names\n",
        "\n",
        "    for i, frame_name in enumerate(real_frame_names):\n",
        "      print(f\"saved real {frame_name.decode('utf-8')} in combined file\")\n",
        "\n",
        "print(f\"Real data appended to {combined_output_path}\")\n"
      ],
      "metadata": {
        "id": "nu3MKW8C0uyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Append Fake Data\n",
        "with h5py.File(fake_output_path, \"r\") as fake_file, h5py.File(combined_output_path, \"a\") as combined_file:\n",
        "    fake_data = fake_file[\"preprocessed_data\"][:]\n",
        "    fake_labels = fake_file[\"labels\"][:]\n",
        "    fake_frame_names = fake_file[\"frame_names\"][:]\n",
        "\n",
        "    current_len = combined_file[\"preprocessed_data\"].shape[0]\n",
        "\n",
        "    combined_file[\"preprocessed_data\"].resize((current_len + fake_data.shape[0]), axis=0)\n",
        "    combined_file[\"labels\"].resize((current_len + fake_labels.shape[0]), axis=0)\n",
        "    combined_file[\"frame_names\"].resize((current_len + fake_frame_names.shape[0]), axis=0)\n",
        "\n",
        "    combined_file[\"preprocessed_data\"][current_len:] = fake_data\n",
        "    combined_file[\"labels\"][current_len:] = fake_labels\n",
        "    combined_file[\"frame_names\"][current_len:] = fake_frame_names\n",
        "\n",
        "    for i, frame_name in enumerate(fake_frame_names):\n",
        "      print(f\"saved fake {frame_name.decode('utf-8')} in combined file\")\n",
        "\n",
        "print(f\"Fake data appended to {combined_output_path}\")"
      ],
      "metadata": {
        "id": "IcYuFpzv1kUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Data Verification**"
      ],
      "metadata": {
        "id": "MCoO3LTB7LT5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.1. Loading Combined Data for Verification**"
      ],
      "metadata": {
        "id": "hlwjv0Xl7T9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the HDF5 file\n",
        "with h5py.File(combined_output_path, \"r\") as f:\n",
        "    # List all datasets in the file\n",
        "    print(\"Datasets in the file:\", list(f.keys()))\n",
        "\n",
        "    # Access the datasets\n",
        "    preprocessed_data = f[\"preprocessed_data\"]\n",
        "    labels = f[\"labels\"]\n",
        "    frame_names = f[\"frame_names\"]\n",
        "\n",
        "    # Print dataset shapes\n",
        "    print(\"Combined Preprocessed data shape:\", preprocessed_data.shape)\n",
        "    print(\"combined Labels shape:\", labels.shape)\n",
        "    print(\"combined Frame names shape:\", frame_names.shape)\n"
      ],
      "metadata": {
        "id": "Cq7wzuPH1nXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.2 Verifying Real Class**"
      ],
      "metadata": {
        "id": "1puVVa3y7eaN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def verify_real_data_against_combined(real_path, combined_path):\n",
        "    with h5py.File(real_path, \"r\") as real_file, h5py.File(combined_path, \"r\") as combined_file:\n",
        "        # Load real data\n",
        "        real_frame_names = [name.decode(\"utf-8\") for name in real_file[\"frame_names\"][:]]\n",
        "        real_labels = real_file[\"labels\"][:]\n",
        "        real_data = real_file[\"preprocessed_data\"][:]\n",
        "\n",
        "        # Load combined data\n",
        "        combined_frame_names = [name.decode(\"utf-8\") for name in combined_file[\"frame_names\"][:]]\n",
        "        combined_labels = combined_file[\"labels\"][:]\n",
        "        combined_data = combined_file[\"preprocessed_data\"][:]\n",
        "\n",
        "        # Check if all real frames are in the combined dataset\n",
        "        missing_frames = [name for name in real_frame_names if name not in combined_frame_names]\n",
        "        if missing_frames:\n",
        "            print(f\"Warning: {len(missing_frames)} real frames are missing in the combined dataset.\")\n",
        "            print(\"Missing frames:\", missing_frames)\n",
        "        else:\n",
        "            print(\"All real frames are present in the combined dataset.\")\n",
        "\n",
        "        # Verify labels and data for real frames\n",
        "        print(\"\\nVerifying labels and data for real frames...\")\n",
        "        for i, frame_name in enumerate(real_frame_names):\n",
        "            if frame_name in combined_frame_names:\n",
        "                combined_index = combined_frame_names.index(frame_name)\n",
        "\n",
        "                # Check label (real data should have label 0)\n",
        "                if combined_labels[combined_index] != 0:\n",
        "                    print(f\"Label mismatch for real frame: {frame_name} (Expected: 0, Found: {combined_labels[combined_index]})\")\n",
        "\n",
        "                # Check preprocessed data\n",
        "                if not np.array_equal(real_data[i], combined_data[combined_index]):\n",
        "                    print(f\"Data mismatch for real frame: {frame_name}\")\n",
        "\n",
        "        print(\"Verification for real data complete.\")\n",
        "\n",
        "\n",
        "verify_real_data_against_combined(real_output_path, combined_output_path)"
      ],
      "metadata": {
        "id": "B-R13eJZ1u6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.3 Verifying Fake Class**"
      ],
      "metadata": {
        "id": "WOXqcC3m7obA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def verify_fake_data_against_combined(fake_path, combined_path):\n",
        "    with h5py.File(fake_path, \"r\") as fake_file, h5py.File(combined_path, \"r\") as combined_file:\n",
        "        # Load fake data\n",
        "        fake_frame_names = [name.decode(\"utf-8\") for name in fake_file[\"frame_names\"][:]]\n",
        "        fake_labels = fake_file[\"labels\"][:]\n",
        "        fake_data = fake_file[\"preprocessed_data\"][:]\n",
        "\n",
        "        # Load combined data\n",
        "        combined_frame_names = [name.decode(\"utf-8\") for name in combined_file[\"frame_names\"][:]]\n",
        "        combined_labels = combined_file[\"labels\"][:]\n",
        "        combined_data = combined_file[\"preprocessed_data\"][:]\n",
        "\n",
        "        # Check if all fake frames are in the combined dataset\n",
        "        missing_frames = [name for name in fake_frame_names if name not in combined_frame_names]\n",
        "        if missing_frames:\n",
        "            print(f\"Warning: {len(missing_frames)} fake frames are missing in the combined dataset.\")\n",
        "            print(\"Missing frames:\", missing_frames)\n",
        "        else:\n",
        "            print(\"All fake frames are present in the combined dataset.\")\n",
        "\n",
        "        # Verify labels and data for fake frames\n",
        "        print(\"\\nVerifying labels and data for fake frames...\")\n",
        "        for i, frame_name in enumerate(fake_frame_names):\n",
        "            if frame_name in combined_frame_names:\n",
        "                combined_index = combined_frame_names.index(frame_name)\n",
        "\n",
        "                # Check label (fake data should have label 1)\n",
        "                if combined_labels[combined_index] != 1:\n",
        "                    print(f\"Label mismatch for fake frame: {frame_name} (Expected: 1, Found: {combined_labels[combined_index]})\")\n",
        "\n",
        "                # Check preprocessed data\n",
        "                if not np.array_equal(fake_data[i], combined_data[combined_index]):\n",
        "                    print(f\"Data mismatch for fake frame: {frame_name}\")\n",
        "\n",
        "        print(\"Verification for fake data complete.\")\n",
        "\n",
        "\n",
        "verify_fake_data_against_combined(fake_output_path, combined_output_path)"
      ],
      "metadata": {
        "id": "ssgGhb5l1vq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.4 Loading as Dataset to check for Duplicate Frames**"
      ],
      "metadata": {
        "id": "fh-Kyu5S7vJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_h5_to_dataframe(file_path):\n",
        "    \"\"\"\n",
        "    Load data from an HDF5 file into a Pandas DataFrame.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the HDF5 file.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing frame_names, labels, and preprocessed_data (if needed).\n",
        "    \"\"\"\n",
        "    with h5py.File(file_path, \"r\") as f:\n",
        "        frame_names = f[\"frame_names\"][:].astype(str)\n",
        "        labels = f[\"labels\"][:]\n",
        "\n",
        "        # Create a DataFrame\n",
        "        df = pd.DataFrame({\n",
        "            \"frame_name\": frame_names,\n",
        "            \"label\": labels,\n",
        "        })\n",
        "\n",
        "    return df\n",
        "\n",
        "combined_df = load_h5_to_dataframe(combined_output_path)"
      ],
      "metadata": {
        "id": "YjRY23z81ydG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_duplicate_frames(combined_df):\n",
        "    \"\"\"\n",
        "    Check for duplicate frames in the combined DataFrame.\n",
        "\n",
        "    Args:\n",
        "        combined_df (pd.DataFrame): DataFrame for the combined data.\n",
        "    \"\"\"\n",
        "    duplicate_frames = combined_df[combined_df.duplicated(\"frame_name\", keep=False)]\n",
        "    if not duplicate_frames.empty:\n",
        "        print(f\"Warning: {len(duplicate_frames)} duplicate frames detected in the combined file.\")\n",
        "        print(\"Duplicate frames:\")\n",
        "        print(duplicate_frames)\n",
        "    else:\n",
        "        print(\"No duplicate frames detected in the combined file.\")\n",
        "\n",
        "check_duplicate_frames(combined_df)"
      ],
      "metadata": {
        "id": "5DbgdUc72DcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Spatial Dataset Creation**"
      ],
      "metadata": {
        "id": "wEcscT1q76rq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "def create_spatial_dataset(file_path):\n",
        "    \"\"\"\n",
        "    Creates a TensorFlow Dataset pipeline for loading spatial data (individual frames) from an HDF5 file.\n",
        "    Skips empty frames (all zeros) and normalizes frames to [0, 1].\n",
        "    Preserves the order of frames and does not batch or shuffle.\n",
        "    \"\"\"\n",
        "    def load_frame_data():\n",
        "        with h5py.File(file_path, \"r\") as f:\n",
        "            frame_names = f[\"frame_names\"][:]  # Shape: (num_frames,)\n",
        "            frames = f[\"preprocessed_data\"][:]  # Shape: (num_frames, 224, 224, 3)\n",
        "            labels = f[\"labels\"][:]  # Shape: (num_frames,)\n",
        "\n",
        "            # Filter out empty frames (all zeros)\n",
        "            non_empty_indices = [i for i, frame in enumerate(frames) if not np.all(frame == 0)]\n",
        "            frames = frames[non_empty_indices]  # Shape: (num_valid_frames, 224, 224, 3)\n",
        "            labels = labels[non_empty_indices]  # Shape: (num_valid_frames,)\n",
        "\n",
        "            # Normalize frames to [0, 1]\n",
        "            frames = frames.astype(np.float32) / 255.0\n",
        "\n",
        "        return frames, labels\n",
        "\n",
        "    # Load all individual frames and labels for spatial dataset\n",
        "    frames, labels = load_frame_data()\n",
        "\n",
        "    # Create a TensorFlow Dataset\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((frames, labels))\n",
        "\n",
        "    # Prefetch the dataset (no batching or shuffling)\n",
        "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "sgpYbGYm2gP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "file_path = \"/content/drive/MyDrive/ff++preprocessed_combined_data.h5\"\n",
        "dataset = create_spatial_dataset(file_path)"
      ],
      "metadata": {
        "id": "ik_8YuCV8Dyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for frame, label in dataset.take(5):  # Check the first 5 elements\n",
        "    print(\"Frame shape:\", frame.shape)  # Shape of the frame\n",
        "    print(\"Label shape:\", label.shape)  # Shape of the label"
      ],
      "metadata": {
        "id": "yHNkraAX2hCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.1 Spatial Dataset Split**"
      ],
      "metadata": {
        "id": "Wm39qqnB8ZZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_list = list(dataset)\n",
        "\n",
        "# Split the dataset into train and validation sets (80% train, 20% validation)\n",
        "train_data, val_data = train_test_split(dataset_list, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the sizes of the splits\n",
        "print(\"Training samples:\", len(train_data))\n",
        "print(\"Validation samples:\", len(val_data))"
      ],
      "metadata": {
        "id": "wDEkpqQH2n_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.2 Spatial Train and Val Saving**"
      ],
      "metadata": {
        "id": "9MtPVfJS8g_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "# Convert the datasets to numpy arrays\n",
        "train_frames = np.array([frame.numpy() for frame, label in train_data])\n",
        "train_labels = np.array([label.numpy() for frame, label in train_data])\n",
        "\n",
        "val_frames = np.array([frame.numpy() for frame, label in val_data])\n",
        "val_labels = np.array([label.numpy() for frame, label in val_data])\n",
        "\n",
        "# Save the training data to an HDF5 file\n",
        "with h5py.File('/content/drive/MyDrive/train_spatial_data.h5', 'w') as f:\n",
        "    f.create_dataset('frames', data=train_frames)\n",
        "    f.create_dataset('labels', data=train_labels)\n",
        "\n",
        "# Save the validation data to an HDF5 file\n",
        "with h5py.File('/content/drive/MyDrive/val_spatial_data.h5', 'w') as f:\n",
        "    f.create_dataset('frames', data=val_frames)\n",
        "    f.create_dataset('labels', data=val_labels)\n",
        "\n",
        "print(\"Training and validation data for Spatial Model saved to HDF5 files.\")"
      ],
      "metadata": {
        "id": "IjVYd_mp2qcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Temporal Dataset Creation**"
      ],
      "metadata": {
        "id": "GBPWneC28tfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_temporal_dataset(file_path):\n",
        "    \"\"\"\n",
        "    Creates a TensorFlow Dataset pipeline for loading data from an HDF5 file.\n",
        "    Skips videos with no valid frames and filters out empty frames (all zeros).\n",
        "    \"\"\"\n",
        "    def load_video_data(video_name):\n",
        "        with h5py.File(file_path, \"r\") as f:\n",
        "            # Get indices of frames for the current video\n",
        "            frame_indices = np.where([name.decode('utf-8').split('_face_')[0].rsplit('_', 1)[0] == video_name for name in f[\"frame_names\"]])[0]\n",
        "            frames = f[\"preprocessed_data\"][frame_indices]  # Shape: (num_frames, 224, 224, 3)\n",
        "            labels = f[\"labels\"][frame_indices]  # Shape: (num_frames,)\n",
        "\n",
        "            # Debug: Print raw frame values\n",
        "            print(f\"Video: {video_name}\")\n",
        "            print(\"Raw frames min:\", np.min(frames))\n",
        "            print(\"Raw frames max:\", np.max(frames))\n",
        "\n",
        "            # Filter out empty frames (all zeros)\n",
        "            non_empty_indices = [i for i, frame in enumerate(frames) if not np.all(frame == 0)]\n",
        "            empty_count = len(frames) - len(non_empty_indices)\n",
        "            if empty_count > 0:\n",
        "                print(f\"Video {video_name}: Filtered out {empty_count} empty frames.\")\n",
        "\n",
        "            # Skip videos with no valid frames\n",
        "            if len(non_empty_indices) == 0:\n",
        "                print(f\"Warning: Video {video_name} has no valid frames. Skipping.\")\n",
        "                return None, None, None\n",
        "\n",
        "            frames = frames[non_empty_indices]\n",
        "            labels = labels[non_empty_indices]\n",
        "\n",
        "            # Ensure labels are consistent\n",
        "            first_label = labels[0]\n",
        "            if not np.all(labels == first_label):\n",
        "                print(f\"Warning: Inconsistent labels in video {video_name}. Using the first label.\")\n",
        "                labels = np.full_like(labels, first_label)\n",
        "\n",
        "            # Convert frames to float32 and normalize to [0, 1]\n",
        "            frames = frames.astype(np.float32) / 255.0\n",
        "\n",
        "            # Debug: Print normalized frame values\n",
        "            print(\"Normalized frames min:\", np.min(frames))\n",
        "            print(\"Normalized frames max:\", np.max(frames))\n",
        "\n",
        "            # Ensure shapes are defined\n",
        "            frames = tf.ensure_shape(frames, [None, 224, 224, 3])  # num_frames can be None\n",
        "            labels = tf.ensure_shape(labels, [None])  # num_frames can be None\n",
        "\n",
        "        return frames, first_label, video_name\n",
        "\n",
        "    # Get unique video names from the HDF5 file\n",
        "    with h5py.File(file_path, \"r\") as f:\n",
        "        unique_video_names = np.unique([name.decode('utf-8').split('_face_')[0].rsplit('_', 1)[0] for name in f[\"frame_names\"]])\n",
        "\n",
        "    # Create a TensorFlow Dataset from the list of video names\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(unique_video_names)\n",
        "\n",
        "    # Map each video name to its frames, label, and video name\n",
        "    dataset = dataset.map(\n",
        "        lambda video_name: tf.py_function(\n",
        "            load_video_data, [video_name], [tf.float32, tf.float32, tf.string]\n",
        "        ),\n",
        "        num_parallel_calls=tf.data.experimental.AUTOTUNE\n",
        "    )\n",
        "\n",
        "    # Filter out videos with no valid frames\n",
        "    dataset = dataset.filter(lambda frames, label, video_name: frames is not None)\n",
        "\n",
        "    # Prefetch the dataset (no batching here)\n",
        "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# Load the dataset\n",
        "dataset = create_temporal_dataset(file_path)"
      ],
      "metadata": {
        "id": "FlqMT5D73YiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the dataset to a list for splitting\n",
        "dataset_list = list(dataset)\n",
        "\n",
        "# Split the dataset into train and validation sets (80% train, 20% validation)\n",
        "train_data, val_data = train_test_split(dataset_list, test_size=0.2, random_state=42)\n",
        "# Print the sizes of the splits\n",
        "print(\"Training samples:\", len(train_data))\n",
        "print(\"Validation samples:\", len(val_data))"
      ],
      "metadata": {
        "id": "o7mK5JfN4kSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop video_name and keep only frames and labels\n",
        "train_data = [(frames, label) for frames, label, _ in train_data]\n",
        "val_data = [(frames, label) for frames, label, _ in val_data]"
      ],
      "metadata": {
        "id": "gqWrNpQz4p6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.1 Saving Temporal Train and Val**"
      ],
      "metadata": {
        "id": "BdyWCrVs9YdS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save train_data to an HDF5 file\n",
        "#getting frames in video sequence for temporal dataset\n",
        "with h5py.File('train_temporal_data.h5', 'w') as f:\n",
        "    for i, (frames, label) in enumerate(train_data):\n",
        "        # Create a group for each video\n",
        "        video_group = f.create_group(f'video_{i}')\n",
        "        # Save frames and label for this video\n",
        "        video_group.create_dataset('frames', data=frames)\n",
        "        video_group.create_dataset('label', data=label)\n",
        "\n",
        "# Save val_data to an HDF5 file\n",
        "with h5py.File('val_temporal_data.h5', 'w') as f:\n",
        "    for i, (frames, label) in enumerate(val_data):\n",
        "        # Create a group for each video\n",
        "        video_group = f.create_group(f'video_{i}')\n",
        "        # Save frames and label for this video\n",
        "        video_group.create_dataset('frames', data=frames)\n",
        "        video_group.create_dataset('label', data=label)"
      ],
      "metadata": {
        "id": "DrxvafcV4qzO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}